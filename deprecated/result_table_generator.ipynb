{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy.stats import friedmanchisquare\n",
    "from scikit_posthocs import posthoc_nemenyi_friedman, posthoc_nemenyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_type = 'Regression'\n",
    "no_algos = 11 if result_type == 'Classification' else 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df = []\n",
    "for result_file in glob('results/aggregated/*.csv'):\n",
    "    if result_type in result_file:\n",
    "        rf_df.append(pd.read_csv(result_file))\n",
    "df = pd.concat(rf_df).drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results = '$' + df.groupby(['dataset', 'base', 'method']).mean()['PM1'].round(2).astype(str) + '\\pm' + df.groupby(['dataset', 'base', 'method']).std()['PM1'].round(2).astype(str) + '$'\n",
    "aggregated_results.unstack(level=0).to_csv('results/all_' + result_type + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_results = df.groupby(['dataset', 'base', 'method']).mean().groupby(['base','method']).mean()[['TriesToOpt','Time']]\n",
    "time_results['MinTime'] = df.groupby(['dataset', 'base', 'method']).mean().groupby(['base','method']).min()[['Time']]\n",
    "time_results['MaxTime'] = df.groupby(['dataset', 'base', 'method']).mean().groupby(['base','method']).max()[['Time']]\n",
    "time_results.to_csv('results/time_' + result_type + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "abalone FriedmanchisquareResult(statistic=1237.118794835008, pvalue=1.8210328822666697e-256)\n",
      "bike FriedmanchisquareResult(statistic=1175.982097976102, pvalue=2.600913655271004e-243)\n",
      "boston FriedmanchisquareResult(statistic=810.1248128907287, pvalue=9.369268661230679e-165)\n",
      "diabetes FriedmanchisquareResult(statistic=567.9626086000221, pvalue=5.1383522627383655e-113)\n",
      "fire FriedmanchisquareResult(statistic=844.4273530575468, pvalue=4.186191883750187e-172)\n",
      "machine FriedmanchisquareResult(statistic=584.6937285698484, pvalue=1.4022049999662132e-116)\n",
      "student FriedmanchisquareResult(statistic=848.0294098208976, pvalue=7.075964263463571e-173)\n"
     ]
    }
   ],
   "source": [
    "datasets = df['dataset'].drop_duplicates().to_list()\n",
    "for dataset in datasets:\n",
    "    df_for_tests = df[['dataset','base','method']].drop_duplicates()\n",
    "    temp_data_for_tests = []\n",
    "    for i, row in df_for_tests.iterrows():\n",
    "        if row.dataset == dataset:\n",
    "            temp_data_for_tests.append(list(df[(df.dataset==row.dataset) & (df.base==row.base) & (df.method==row.method)]['PM1']))\n",
    "    print(dataset, friedmanchisquare(*temp_data_for_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df1 = []\n",
    "rf_df2 = []\n",
    "for i, result_file in enumerate(glob('results/aggregated/*.csv')):\n",
    "    if result_type in result_file:\n",
    "        if i > (len(glob('results/aggregated/*.csv'))/2):\n",
    "            rf_df1.append(pd.read_csv(result_file))\n",
    "        else:\n",
    "            rf_df2.append(pd.read_csv(result_file))\n",
    "\n",
    "df1 = pd.concat(rf_df1).drop('Unnamed: 0', axis = 1)\n",
    "df2 = pd.concat(rf_df2).drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dataset                                   abalone_         bike_    boston_  \\\n",
       "base    method                                                                \n",
       "000 rf  000 all                           4.764343  4.508402e+05  11.175558   \n",
       "001 knn 000 all                           5.917103  8.043019e+05  26.192931   \n",
       "        002 intercorrelation              6.273205  9.139209e+05  26.073213   \n",
       "        003 feature importance selection  5.422282  7.080720e+05  20.044577   \n",
       "        004 l1                            6.218799  8.169518e+05  20.139768   \n",
       "        005 relieff selection             5.566142  1.825072e+06  19.987322   \n",
       "        006 forward selection             5.544419  1.303517e+06  21.739054   \n",
       "        007 backward selection            5.541839  1.169805e+06  20.080230   \n",
       "        008 stepwise selection            5.543897  1.182393e+06  20.150008   \n",
       "        009 bayesian selection            5.531400  7.914195e+05  19.562863   \n",
       "        010 correlation weighting         5.683070  6.208102e+05  20.586426   \n",
       "        011 feature importance weighting  5.557096  8.155585e+05  19.976539   \n",
       "        012 relieff weighting             5.543361  1.157508e+06  20.018558   \n",
       "        013 bayesian weighting            5.233078  5.545236e+05  15.985604   \n",
       "\n",
       "dataset                                     diabetes_     fire_      machine_  \\\n",
       "base    method                                                                  \n",
       "000 rf  000 all                           3366.645782  2.215851   4476.904780   \n",
       "001 knn 000 all                           3351.298596  2.042398  10568.905302   \n",
       "        002 intercorrelation              3331.938500  2.034876  10733.434979   \n",
       "        003 feature importance selection  3801.438423  2.109935  10013.722006   \n",
       "        004 l1                            3245.766551 -1.000000   9113.271263   \n",
       "        005 relieff selection             3250.884875  2.044705  11239.483200   \n",
       "        006 forward selection             3424.378642  2.077612  10361.290293   \n",
       "        007 backward selection            3270.026993  2.077293  10248.455171   \n",
       "        008 stepwise selection            3314.302524  2.076431  10131.789318   \n",
       "        009 bayesian selection            3181.231185  1.937094   7759.183442   \n",
       "        010 correlation weighting         3246.631623  2.052402   9500.974505   \n",
       "        011 feature importance weighting  3245.629297  2.049432   9142.617740   \n",
       "        012 relieff weighting             3251.573938  2.065308  10547.970100   \n",
       "        013 bayesian weighting            2880.369426  1.870549   6711.558152   \n",
       "\n",
       "dataset                                    student_   abalone          bike  \\\n",
       "base    method                                                                \n",
       "000 rf  000 all                           15.252728  4.765347  4.460808e+05   \n",
       "001 knn 000 all                           19.295810  5.872726  8.245619e+05   \n",
       "        002 intercorrelation              19.295810  6.208608  9.205672e+05   \n",
       "        003 feature importance selection  21.540813  5.394071  7.403873e+05   \n",
       "        004 l1                            19.541044  6.174924  8.490095e+05   \n",
       "        005 relieff selection             18.547160  5.518201  1.786537e+06   \n",
       "        006 forward selection             19.705728  5.505612  1.250821e+06   \n",
       "        007 backward selection            18.249218  5.495499  1.205888e+06   \n",
       "        008 stepwise selection            19.079174  5.496323  1.217179e+06   \n",
       "        009 bayesian selection            16.404120  5.484877  8.206247e+05   \n",
       "        010 correlation weighting         18.768985  5.644057  6.258672e+05   \n",
       "        011 feature importance weighting  18.543548  5.509009  8.471582e+05   \n",
       "        012 relieff weighting             18.173847  5.497148  1.190827e+06   \n",
       "        013 bayesian weighting            14.886868  5.197224  5.568685e+05   \n",
       "\n",
       "dataset                                      boston     diabetes      fire  \\\n",
       "base    method                                                               \n",
       "000 rf  000 all                           10.474228  3364.490384  2.147620   \n",
       "001 knn 000 all                           25.441756  3296.557428  1.962740   \n",
       "        002 intercorrelation              25.216559  3274.892291  1.961487   \n",
       "        003 feature importance selection  19.643246  3743.741127  2.033740   \n",
       "        004 l1                            19.375376  3235.532876 -1.000000   \n",
       "        005 relieff selection             19.232074  3243.579731  1.959947   \n",
       "        006 forward selection             21.610771  3301.777146  2.028616   \n",
       "        007 backward selection            19.323592  3260.399926  1.988895   \n",
       "        008 stepwise selection            19.938982  3265.565985  2.005495   \n",
       "        009 bayesian selection            18.860044  3157.642539  1.869729   \n",
       "        010 correlation weighting         20.506430  3243.555027  1.986638   \n",
       "        011 feature importance weighting  19.230657  3236.415908  1.966037   \n",
       "        012 relieff weighting             19.247662  3237.875360  1.988970   \n",
       "        013 bayesian weighting            15.574918  2829.277256  1.801900   \n",
       "\n",
       "dataset                                        machine    student  \n",
       "base    method                                                     \n",
       "000 rf  000 all                            4893.608944  15.192445  \n",
       "001 knn 000 all                           10454.758650  18.597749  \n",
       "        002 intercorrelation              10611.421916  18.597749  \n",
       "        003 feature importance selection  10103.031350  20.810456  \n",
       "        004 l1                             8973.803548  18.672499  \n",
       "        005 relieff selection             11169.613733  18.060439  \n",
       "        006 forward selection             10069.584277  18.657237  \n",
       "        007 backward selection             9376.058246  17.539984  \n",
       "        008 stepwise selection             9764.439105  18.120478  \n",
       "        009 bayesian selection             7579.681117  15.688685  \n",
       "        010 correlation weighting          9304.747321  18.035516  \n",
       "        011 feature importance weighting   8982.529797  17.879418  \n",
       "        012 relieff weighting             10002.234554  17.497750  \n",
       "        013 bayesian weighting             6783.428169  14.344978  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>abalone_</th>\n      <th>bike_</th>\n      <th>boston_</th>\n      <th>diabetes_</th>\n      <th>fire_</th>\n      <th>machine_</th>\n      <th>student_</th>\n      <th>abalone</th>\n      <th>bike</th>\n      <th>boston</th>\n      <th>diabetes</th>\n      <th>fire</th>\n      <th>machine</th>\n      <th>student</th>\n    </tr>\n    <tr>\n      <th>base</th>\n      <th>method</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000 rf</th>\n      <th>000 all</th>\n      <td>4.764343</td>\n      <td>4.508402e+05</td>\n      <td>11.175558</td>\n      <td>3366.645782</td>\n      <td>2.215851</td>\n      <td>4476.904780</td>\n      <td>15.252728</td>\n      <td>4.765347</td>\n      <td>4.460808e+05</td>\n      <td>10.474228</td>\n      <td>3364.490384</td>\n      <td>2.147620</td>\n      <td>4893.608944</td>\n      <td>15.192445</td>\n    </tr>\n    <tr>\n      <th rowspan=\"13\" valign=\"top\">001 knn</th>\n      <th>000 all</th>\n      <td>5.917103</td>\n      <td>8.043019e+05</td>\n      <td>26.192931</td>\n      <td>3351.298596</td>\n      <td>2.042398</td>\n      <td>10568.905302</td>\n      <td>19.295810</td>\n      <td>5.872726</td>\n      <td>8.245619e+05</td>\n      <td>25.441756</td>\n      <td>3296.557428</td>\n      <td>1.962740</td>\n      <td>10454.758650</td>\n      <td>18.597749</td>\n    </tr>\n    <tr>\n      <th>002 intercorrelation</th>\n      <td>6.273205</td>\n      <td>9.139209e+05</td>\n      <td>26.073213</td>\n      <td>3331.938500</td>\n      <td>2.034876</td>\n      <td>10733.434979</td>\n      <td>19.295810</td>\n      <td>6.208608</td>\n      <td>9.205672e+05</td>\n      <td>25.216559</td>\n      <td>3274.892291</td>\n      <td>1.961487</td>\n      <td>10611.421916</td>\n      <td>18.597749</td>\n    </tr>\n    <tr>\n      <th>003 feature importance selection</th>\n      <td>5.422282</td>\n      <td>7.080720e+05</td>\n      <td>20.044577</td>\n      <td>3801.438423</td>\n      <td>2.109935</td>\n      <td>10013.722006</td>\n      <td>21.540813</td>\n      <td>5.394071</td>\n      <td>7.403873e+05</td>\n      <td>19.643246</td>\n      <td>3743.741127</td>\n      <td>2.033740</td>\n      <td>10103.031350</td>\n      <td>20.810456</td>\n    </tr>\n    <tr>\n      <th>004 l1</th>\n      <td>6.218799</td>\n      <td>8.169518e+05</td>\n      <td>20.139768</td>\n      <td>3245.766551</td>\n      <td>-1.000000</td>\n      <td>9113.271263</td>\n      <td>19.541044</td>\n      <td>6.174924</td>\n      <td>8.490095e+05</td>\n      <td>19.375376</td>\n      <td>3235.532876</td>\n      <td>-1.000000</td>\n      <td>8973.803548</td>\n      <td>18.672499</td>\n    </tr>\n    <tr>\n      <th>005 relieff selection</th>\n      <td>5.566142</td>\n      <td>1.825072e+06</td>\n      <td>19.987322</td>\n      <td>3250.884875</td>\n      <td>2.044705</td>\n      <td>11239.483200</td>\n      <td>18.547160</td>\n      <td>5.518201</td>\n      <td>1.786537e+06</td>\n      <td>19.232074</td>\n      <td>3243.579731</td>\n      <td>1.959947</td>\n      <td>11169.613733</td>\n      <td>18.060439</td>\n    </tr>\n    <tr>\n      <th>006 forward selection</th>\n      <td>5.544419</td>\n      <td>1.303517e+06</td>\n      <td>21.739054</td>\n      <td>3424.378642</td>\n      <td>2.077612</td>\n      <td>10361.290293</td>\n      <td>19.705728</td>\n      <td>5.505612</td>\n      <td>1.250821e+06</td>\n      <td>21.610771</td>\n      <td>3301.777146</td>\n      <td>2.028616</td>\n      <td>10069.584277</td>\n      <td>18.657237</td>\n    </tr>\n    <tr>\n      <th>007 backward selection</th>\n      <td>5.541839</td>\n      <td>1.169805e+06</td>\n      <td>20.080230</td>\n      <td>3270.026993</td>\n      <td>2.077293</td>\n      <td>10248.455171</td>\n      <td>18.249218</td>\n      <td>5.495499</td>\n      <td>1.205888e+06</td>\n      <td>19.323592</td>\n      <td>3260.399926</td>\n      <td>1.988895</td>\n      <td>9376.058246</td>\n      <td>17.539984</td>\n    </tr>\n    <tr>\n      <th>008 stepwise selection</th>\n      <td>5.543897</td>\n      <td>1.182393e+06</td>\n      <td>20.150008</td>\n      <td>3314.302524</td>\n      <td>2.076431</td>\n      <td>10131.789318</td>\n      <td>19.079174</td>\n      <td>5.496323</td>\n      <td>1.217179e+06</td>\n      <td>19.938982</td>\n      <td>3265.565985</td>\n      <td>2.005495</td>\n      <td>9764.439105</td>\n      <td>18.120478</td>\n    </tr>\n    <tr>\n      <th>009 bayesian selection</th>\n      <td>5.531400</td>\n      <td>7.914195e+05</td>\n      <td>19.562863</td>\n      <td>3181.231185</td>\n      <td>1.937094</td>\n      <td>7759.183442</td>\n      <td>16.404120</td>\n      <td>5.484877</td>\n      <td>8.206247e+05</td>\n      <td>18.860044</td>\n      <td>3157.642539</td>\n      <td>1.869729</td>\n      <td>7579.681117</td>\n      <td>15.688685</td>\n    </tr>\n    <tr>\n      <th>010 correlation weighting</th>\n      <td>5.683070</td>\n      <td>6.208102e+05</td>\n      <td>20.586426</td>\n      <td>3246.631623</td>\n      <td>2.052402</td>\n      <td>9500.974505</td>\n      <td>18.768985</td>\n      <td>5.644057</td>\n      <td>6.258672e+05</td>\n      <td>20.506430</td>\n      <td>3243.555027</td>\n      <td>1.986638</td>\n      <td>9304.747321</td>\n      <td>18.035516</td>\n    </tr>\n    <tr>\n      <th>011 feature importance weighting</th>\n      <td>5.557096</td>\n      <td>8.155585e+05</td>\n      <td>19.976539</td>\n      <td>3245.629297</td>\n      <td>2.049432</td>\n      <td>9142.617740</td>\n      <td>18.543548</td>\n      <td>5.509009</td>\n      <td>8.471582e+05</td>\n      <td>19.230657</td>\n      <td>3236.415908</td>\n      <td>1.966037</td>\n      <td>8982.529797</td>\n      <td>17.879418</td>\n    </tr>\n    <tr>\n      <th>012 relieff weighting</th>\n      <td>5.543361</td>\n      <td>1.157508e+06</td>\n      <td>20.018558</td>\n      <td>3251.573938</td>\n      <td>2.065308</td>\n      <td>10547.970100</td>\n      <td>18.173847</td>\n      <td>5.497148</td>\n      <td>1.190827e+06</td>\n      <td>19.247662</td>\n      <td>3237.875360</td>\n      <td>1.988970</td>\n      <td>10002.234554</td>\n      <td>17.497750</td>\n    </tr>\n    <tr>\n      <th>013 bayesian weighting</th>\n      <td>5.233078</td>\n      <td>5.545236e+05</td>\n      <td>15.985604</td>\n      <td>2880.369426</td>\n      <td>1.870549</td>\n      <td>6711.558152</td>\n      <td>14.886868</td>\n      <td>5.197224</td>\n      <td>5.568685e+05</td>\n      <td>15.574918</td>\n      <td>2829.277256</td>\n      <td>1.801900</td>\n      <td>6783.428169</td>\n      <td>14.344978</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data_for_nemenyi_test = df1.groupby(['dataset', 'base', 'method']).mean()['PM1'].unstack(level=0).join(df2.groupby(['dataset', 'base', 'method']).mean()['PM1'].unstack(level=0), lsuffix='_')\n",
    "data_for_nemenyi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dataset                                   ne_fri_test  ne_fri_test_bool\n",
       "base    method                                                         \n",
       "000 rf  000 all                              0.900000             False\n",
       "001 knn 000 all                              0.010668              True\n",
       "        002 intercorrelation                 0.006537              True\n",
       "        003 feature importance selection     0.036807              True\n",
       "        004 l1                               0.506161             False\n",
       "        005 relieff selection                0.081451             False\n",
       "        006 forward selection                0.001159              True\n",
       "        007 backward selection               0.327854             False\n",
       "        008 stepwise selection               0.045216              True\n",
       "        009 bayesian selection               0.900000             False\n",
       "        010 correlation weighting            0.327854             False\n",
       "        011 feature importance weighting     0.791954             False\n",
       "        012 relieff weighting                0.371999             False\n",
       "        013 bayesian weighting               1.000000             False"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>ne_fri_test</th>\n      <th>ne_fri_test_bool</th>\n    </tr>\n    <tr>\n      <th>base</th>\n      <th>method</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000 rf</th>\n      <th>000 all</th>\n      <td>0.900000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th rowspan=\"13\" valign=\"top\">001 knn</th>\n      <th>000 all</th>\n      <td>0.010668</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>002 intercorrelation</th>\n      <td>0.006537</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>003 feature importance selection</th>\n      <td>0.036807</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>004 l1</th>\n      <td>0.506161</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>005 relieff selection</th>\n      <td>0.081451</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>006 forward selection</th>\n      <td>0.001159</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>007 backward selection</th>\n      <td>0.327854</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>008 stepwise selection</th>\n      <td>0.045216</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>009 bayesian selection</th>\n      <td>0.900000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>010 correlation weighting</th>\n      <td>0.327854</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>011 feature importance weighting</th>\n      <td>0.791954</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>012 relieff weighting</th>\n      <td>0.371999</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>013 bayesian weighting</th>\n      <td>1.000000</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data_for_nemenyi_test = df.groupby(['dataset', 'base', 'method']).mean()['PM1'].unstack(level=0)\n",
    "data_for_nemenyi_test['ne_fri_test'] = list(posthoc_nemenyi_friedman(data_for_nemenyi_test.to_numpy().T)[no_algos])\n",
    "data_for_nemenyi_test['ne_fri_test_bool'] = data_for_nemenyi_test['ne_fri_test'] < 0.05\n",
    "data_for_nemenyi_test[['ne_fri_test', 'ne_fri_test_bool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dataset                                   ne_fri_test  ne_fri_test_bool\n",
       "base    method                                                         \n",
       "000 rf  000 all                              0.900000             False\n",
       "001 knn 000 all                              0.002632              True\n",
       "        002 intercorrelation                 0.001218              True\n",
       "        003 feature importance selection     0.018864              True\n",
       "        004 l1                               0.527344             False\n",
       "        005 relieff selection                0.015223              True\n",
       "        006 forward selection                0.001000              True\n",
       "        007 backward selection               0.251056             False\n",
       "        008 stepwise selection               0.028538              True\n",
       "        009 bayesian selection               0.900000             False\n",
       "        010 correlation weighting            0.285370             False\n",
       "        011 feature importance weighting     0.756485             False\n",
       "        012 relieff weighting                0.165830             False\n",
       "        013 bayesian weighting               1.000000             False"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>ne_fri_test</th>\n      <th>ne_fri_test_bool</th>\n    </tr>\n    <tr>\n      <th>base</th>\n      <th>method</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000 rf</th>\n      <th>000 all</th>\n      <td>0.900000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th rowspan=\"13\" valign=\"top\">001 knn</th>\n      <th>000 all</th>\n      <td>0.002632</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>002 intercorrelation</th>\n      <td>0.001218</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>003 feature importance selection</th>\n      <td>0.018864</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>004 l1</th>\n      <td>0.527344</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>005 relieff selection</th>\n      <td>0.015223</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>006 forward selection</th>\n      <td>0.001000</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>007 backward selection</th>\n      <td>0.251056</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>008 stepwise selection</th>\n      <td>0.028538</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>009 bayesian selection</th>\n      <td>0.900000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>010 correlation weighting</th>\n      <td>0.285370</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>011 feature importance weighting</th>\n      <td>0.756485</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>012 relieff weighting</th>\n      <td>0.165830</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>013 bayesian weighting</th>\n      <td>1.000000</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data_for_nemenyi_test = df.groupby(['dataset', 'base', 'method']).mean()['PM1'].unstack(level=0)\n",
    "data_for_nemenyi_test['repl_d1'] = data_for_nemenyi_test['abalone']\n",
    "data_for_nemenyi_test['repl_d1'] = data_for_nemenyi_test['bike']\n",
    "data_for_nemenyi_test['repl_d1'] = data_for_nemenyi_test['boston']\n",
    "data_for_nemenyi_test['repl_d1'] = data_for_nemenyi_test['diabetes']\n",
    "data_for_nemenyi_test['repl_d1'] = data_for_nemenyi_test['fire']\n",
    "data_for_nemenyi_test['repl_d1'] = data_for_nemenyi_test['machine']\n",
    "data_for_nemenyi_test['ne_fri_test'] = list(posthoc_nemenyi_friedman(data_for_nemenyi_test.to_numpy().T)[no_algos])\n",
    "data_for_nemenyi_test['ne_fri_test_bool'] = data_for_nemenyi_test['ne_fri_test'] < 0.05\n",
    "data_for_nemenyi_test[['ne_fri_test', 'ne_fri_test_bool']]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitfd7a0ac058464de9b3e7ec2171f1e444",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}